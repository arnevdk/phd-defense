\documentclass{kul-ulille-beamer}
%\setbeameroption{show notes on second screen=right} % Both


%% Preamble ===================================================================
\usepackage{defense}

\addbibresource{references.bib}

\title{%
  A visual Brain-Computer Interface \\
  for gaze-free communication
}
\author{Arne Van Den Kerchove}
\date{December 16, 2024}

\begin{document}

% =============================================================================

\titleframe

% =============================================================================

\begin{frame}
  \frametitle{The Locked-in Syndrome}
  \centering
  \begin{minipage}[c]{.4\textwidth}
    \small
    \raggedright
    Complete paralysis, \\ \emph{impaired communication}
    \bigskip

    Due to
    \begin{itemize}
      \item Stroke
      \item Traumatic brain injury
      \item Neurodegenerative diseases
      \item \ldots
    \end{itemize}
    \bigskip

  Assistive technology
  \bigskip

  A Brain-Computer Interface (BCI) bypasses muscle activity

 \end{minipage}\hfill%
  \begin{minipage}[c]{.5\textwidth}
    \includegraphics[width=\textwidth]{figures/intro/damien.pdf}
  \end{minipage}
\end{frame}
\begin{frame}[noframenumbering]
  \frametitle{The Locked-in Syndrome}
  \centering
  \begin{minipage}[c]{.4\textwidth}
    \small
    \raggedright
    Complete paralysis, \\ \emph{impaired communication}
    \bigskip

    Due to
    \begin{itemize}
      \item Stroke
      \item Traumatic brain injury
      \item Neurodegenerative diseases
      \item \ldots
    \end{itemize}
    \bigskip

  Assistive technology
  \bigskip

    A \emph{Brain-Computer Interface} (BCI) bypasses muscle activity

 \end{minipage}\hfill%
  \begin{minipage}[c]{.5\textwidth}
    \includegraphics[width=\textwidth]{figures/intro/damien_annot.pdf}
  \end{minipage}
\end{frame}




\note{%
  \begin{itemize}
    \item Some people cannot communicate
    \item Lis:  loss of nearly all voluntary control over muscles.
    \item no speech or typing
    \item require assistive technology
    \item improve QoL
    \item like eye tracker or muscle controlled switch, depending on residual
      control and impairment cannot always use this
    Â«

  \end{itemize}
}
%
\begin{frame}
  \frametitle{The Brain-Computer Interface}
  \schema{figures/intro/bci.pdf}
\end{frame}


\begin{frame}[c]
  \frametitle{Research question}
  \centering

  \begin{minipage}{.8\textwidth}
  \centering
  \huge
  How can we optimize \emph{BCI}  assistive technology design  to make it more
    \emph{efficient} and  \emph{accessible}?
  \end{minipage}

\end{frame}

\note{
  accessible: more people can use it
}



% =============================================================================

\outline{BCI design}{figures/outline_design.pdf}
{
  \setbeamercolor{background canvas}{bg=mylightgray}
  \begin{frame}
  \frametitle{BCI design}
    \schema{figures/outline.pdf}
  \end{frame}
}

\begin{frame}[c]
  \frametitle{Recording the brain activity}
  \schema{figures/intro/recording_modalities.pdf}
  \hfill
  \aside{%
    \emph{EEG}  measures the \\ electrical field on the
    scalp:
    \begin{itemize}
      \item[\textcolor{mygreen}{+}] Non-invasive
      \item[\textcolor{mygreen}{+}] Cheap
      \item[\textcolor{myred}{--}] Limited resolution
      \item[\textcolor{myred}{--}] Low signal-to-noise ratio
    \end{itemize}
  }
\end{frame}



\begin{frame}[c]
  \frametitle{BCI paradigms for communication}
  \begin{minipage}[c]{.5\textwidth}
    \footnotesize
    \input{figures/intro/paradigms.tikz.tex}
  \end{minipage}\hfill%

  \aside{%
    \small
    %\emph[accent3]{Passive} BCIs not meant for communication
      \smallskip

      \emph[accent1]{Active} BCIs
      \begin{itemize}
        \footnotesize
        \item[\textcolor{mygreen}{+}] Natural
        \item[\textcolor{myred}{--}] Invasive for high speed
      \end{itemize}
      \bigskip

      \emph[accent2]{Reactive}
      \begin{itemize}
        \footnotesize
        \item[\textcolor{myred}{--}] Continuous stimulation
        \item[\textcolor{mygreen}{+}] Fast stimulation
        \item[\textcolor{mygreen}{+}] Suited for EEG
      \end{itemize}
      \bigskip

      Fast communication with \\ \emph{visual reactive} paradigm
    }
\end{frame}
\note{%
  \begin{itemize}
    \item passive BCIs are not meant for communication
    \item categorized participation and stimulation
    \item performing a specific task
    \item brain activity from task can be decoded
  \end{itemize}
}

\begin{frame}
  \frametitle{The visual event-related potential (ERP)  paradigm}
  \begin{minipage}[c]{.4\textwidth}
    \includegraphics[width=\textwidth]{figures/intro/oddball.pdf}
    \smallskip

    \begin{tikzpicture}
      \node at (current page.north east) [%
        anchor=north east,
        text width=7cm,
        fill=white, opacity=1,
        xshift=1cm,
        yshift=-.5cm,
        thin
      ]{%
        \input{figures/intro/erp.tikz.tex}
      };
    \end{tikzpicture}

  \end{minipage}\hfill%
  \begin{minipage}[c]{.5\textwidth}
    \begin{enumerate}
      \item Stimuli flash one by one
      \smallskip
      \item Flashes evoke ERPs
      \smallskip
      \item User attends a stimulus
      \smallskip
      \item ERP components are \\ modulated by attention
      \smallskip
      \item Decode target based on \\ timing and components
    \end{enumerate}
  \end{minipage}
\end{frame}


% =============================================================================

\outline{\emph{C1.} Spatial-temporal ERP decoding}{figures/outline_decode.pdf}
\begin{frame}[c]
  \frametitle{\emph{Problem:} ERP responses can be difficult to extract}
  \begin{minipage}[c]{.5\textwidth}

    Strong noise \ergo machine learning decoders
    \begin{itemize}
      \itemnega High number of features
      \itemnega Low sample size for short calibration
    \end{itemize}
    \bigskip

    \emph{Solution}: incorporate original \\ data structure
    \begin{itemize}
      \itemposi Regularization
      \itemposi Fast training
    \end{itemize}


  \end{minipage}\hfill%
  \begin{minipage}[c]{.4\textwidth}
    \centering

    \emph{Data}\smallskip

    \includegraphics[width=\textwidth]{figures/decode/epoch.pdf}

    \downarrow\smallskip

    \emph{Features}\smallskip

    \includegraphics[width=.9\textwidth]{figures/decode/features.pdf}

  \end{minipage}
\end{frame}

\begin{frame}[c]
  \frametitle{Covariance matrix regularization \\
  {\tiny\cite{VanDenKerchove2022}}}
  \begin{minipage}[c]{.3\textwidth}
  \includegraphics[width=\textwidth]{figures/decode/emp_cov_label.png}
  \end{minipage}
  $=$
  \begin{minipage}[c]{.3\textwidth}
    \begin{minipage}[c]{.4\textwidth}
      \includegraphics[width=\textwidth]{figures/decode/sp_cov_2.png}
    \end{minipage}
  $\otimes$
    \begin{minipage}[c]{.4\textwidth}
      \includegraphics[width=\textwidth]{figures/decode/tmp_cov_2.png}
    \end{minipage}
  \end{minipage}\hfill
  \aside{
    Linear decoders require covariance estimation
    \bigskip

    Imprecise due to high number of features
    \bigskip

    Repetitive structure in channels and time
    \bigskip

    Fast computation
    \bigskip

    Improvement for short calibration time

  }


\end{frame}

\begin{frame}
  \frametitle{Spatial-temporal feature extraction}

  \begin{minipage}[t]{.35\linewidth}
		\centering
		\begin{tikzpicture}[y=-1cm]
			\begin{scope}[shift={(-1,0)}]
        \TensorThree{$\ten{X}$}{\rotatebox{90}{\small channels}}{\small time points}{}{2}{2}{0}
				\node at (3.2,.5, 2) {$\rightarrow$};
				\begin{scope}[shift={(3.25,0.25)}]
					\TensorThree{$\ten{G}$}{}{}{}{1}{1}{0}
				\end{scope}
				\node at (4.2,1.25, 2) {$\downarrow$};
				\begin{scope}[shift={(3,2)}]
					\TensorTwo{classifier}{}{}{1.5}{.5}
				\end{scope}
			\end{scope}
    \end{tikzpicture}
    \bigskip

    \raggedright\small
    Directly operates on structured data
    \begin{itemize}
      \item Extract features separately in space and time
    \end{itemize}
    {\tiny\cite{Phan2010}}
	\end{minipage}\hfill%
  \vrule\hfill%
  \begin{minipage}[t]{.55\textwidth}
    \centering
		\begin{tikzpicture}[y=-1cm]
			\begin{scope}[shift={(-1,0)}]
				\TensorThree{$\ten{X}$}{}{}{}{2}{2}{0}
				\node at (3.2,.5, 2) {$\rightarrow$};
				\begin{scope}[shift={(3.25,0.25)}]
					\TensorThree{$\ten{G}^{(1)}$}{}{}{}{1}{1}{0}
				\end{scope}
				\node at (5.75,.5,2) {$,\cdots,$};
				\begin{scope}[shift={(6.25,0.25)}]
					\TensorThree{$\ten{G}^{(B)}$}{}{}{}{1}{1}{0}
				\end{scope}
				\node at (4.2,1.25, 2) {$\downarrow$};
				\node at (5.7,1.25, 2) {$\downarrow$};
				\node at (7.2,1.25, 2) {$\downarrow$};
				\begin{scope}[shift={(3,2)}]
					\TensorTwo{classifier}{}{}{4.5}{.5}
				\end{scope}
			\end{scope}
    \end{tikzpicture}
    \smallskip

    \begin{minipage}[t]{.5\textwidth}
      \small
      \posi\ \ More flexible
      \smallskip

      \posi\ \ Retains structure
      \smallskip

      {\tiny\cite{VanDenKerchovesubmitted}}
    \end{minipage}\hfill%
    \begin{minipage}[t]{.5\textwidth}
      \small\raggedright
      \nega\ \ More parameters
      \smallskip

      \ergo Heuristic model selection
      \smallskip

      Validated with 4 open datasets, improvement over base model
    \end{minipage}
  \end{minipage}

\end{frame}
\note{
  Another method: consider that we keep all data in its original shape and find
  separate transformations for space and for time
}


% =============================================================================

\outline{\emph{C2.} Eye movement independence}{figures/outline_gaze.pdf}


\begin{frame}
  \frametitle{\emph{Problem:} Eye motor impairment \\  prevents gazing at targets}

  \begin{minipage}[c]{.4\textwidth}
    \raggedright
    Impairment affects BCI operation
    {\tiny\cite{FriedOken2020}}
    {\small
    \begin{itemize}
      \footnotesize
      \item Discomfort fixating
      \item Restricted movement
      \item Involuntary movements
    \end{itemize}
    }
    No direct gaze
    \bigskip
    \bigskip

    Decoding relies on \emph{visual ERP} components \\ {\tiny\cite{Treder2010}}
  \end{minipage}\hfill%
  \begin{minipage}[c]{.4\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/intro/covert_performance_drop/brunner_2010_line.png}

    {\tiny\cite{RonAngevin2019}}


	\end{minipage}
\end{frame}

\note{
  \begin{itemize}
    \item Explain axes
    \item Accuracy is lower when not gazing directly
    \item Even below 80\% usability threshold
  \end{itemize}

}


\begin{frame}
  \frametitle{Covert visuospatial attention experiment \\
    {\tiny\cite{VanDenKerchove2024}}}
    \centering
    \small


    \hfill
    \begin{minipage}[c]{.25\textwidth}
    \input{figures/covert/interface_3.tikz.tex}
      Hex-o-Spell {\tiny\cite{Treder2010}}
    \end{minipage}\hfill%
    \begin{minipage}[c]{.35\textwidth}
      \includegraphics[width=\textwidth]{figures/covert/timeline.pdf}
    \end{minipage}
    \hfill%
    \bigskip


    \centering
    \begin{minipage}{.6\textwidth}
    \begin{minipage}{.3\textwidth}
      overt
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_overt.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      covert
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_covert.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      \small
      Split
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_split.pdf}
    \end{minipage}%
    \end{minipage}

\end{frame}

\begin{frame}
  \frametitle{Evoked ERP components}
  \footnotesize
  \begin{minipage}[t]{.45\textwidth}
    \includegraphics[width=.2\textwidth]{figures/covert/attention_overt.pdf}
    \hspace{.5em}
    \emph{Overt} VSA
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_overt_cluster-1.pdf}
    Attention-based P3 (central-parietal)
    \bigskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_overt_cluster-0.pdf}
    Visual early components (occipital)
    \smallskip

    F-statistic cluster-based permutation tests
  \end{minipage}\hfill%
  \begin{minipage}[t]{.45\textwidth}
    \includegraphics[width=.2\textwidth]{figures/covert/attention_covert.pdf}
    \hspace{.5em}
    \emph{Covert} VSA
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_covert_cluster-0.pdf}
    \smallskip

    \includegraphics[width=.2\textwidth]{figures/covert/attention_split.pdf}
    \hspace{.5em}
    \emph{Split} VSA
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_split_cluster-0.pdf}

  \end{minipage}
\end{frame}


%% =============================================================================

\outline{\emph{C3.} Eye movement independent decoding}{figures/outline_decode.pdf}

\begin{frame}[c]
  \frametitle{\emph{Problem:} Latency jitter decreases performance \\ in covert and split
  attention}
  \begin{minipage}{.4\textwidth}
    \input{figures/covert/smearing.tikz.tex}
  \end{minipage}\hfill%
  \begin{minipage}{.55\textwidth}
    \small
    \centering
    {\centering\resizebox{.7\textwidth}{!}{%
    \small
    %CVSA-ERP (our dataset) \hspace{3.5em} BNCI2014-009
    %\smallskip

    \input{figures/covert/jitter.pgf}
    }}

    \begin{itemize}
      %\item Classifier-based latency estimation {\tiny\cite{Mowla2017}}
      \item Higher jitter when eye movement independent
      \item Contributes to low accuracy \\ {\tiny\cite{Arico2014}}
      \item Can this be \emph{accounted for}?
    \end{itemize}

  \end{minipage}

\end{frame}
\note{
  Using a technique called CBLE extract latencies of single-trial ERPs
}

\begin{frame}
  \frametitle{Latency estimation and alignment}
  \begin{minipage}{.3\textwidth}
    \emph{Before} alignment
    \smallskip

    \includegraphics[height=1.3\textwidth]{figures/covert/split_p3_latency_subject.pdf}
  \end{minipage}
  \begin{minipage}{.3\textwidth}
    \emph{After} alignment
    \smallskip

    \includegraphics[height=1.3\textwidth]{figures/covert/split_p3_latency_subject_aligned.pdf}
  \end{minipage}
  \aside{%
    Developed enhanced ERP latency estimation method
    {\tiny\cite{VanDenKerchove2024,Mowla2017}}
    \bigskip

    Iterative alignment
    \bigskip

    Alignment improves SNR in simulated data
    \bigskip

    Transfer to real data?
  }
\end{frame}


\begin{frame}
  \frametitle{Application to eye movement independent \\ decoding}
  \begin{minipage}{.6\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/covert/roc_auc_diff.pdf}
  \end{minipage}\hfill
  \aside{%
    Applicable as decoder
    \bigskip

    Within-subject, cross-validated single-trial evaluation (ROC-AUC), 2 datasets
    \bigskip

    Compared with state-\\of-the art decoders \\
    {\tiny\cite{Mowla2017,Sosulski2022}}
    \bigskip

    Improves decoding performance independent from eye movement


  }
\end{frame}
\note{Across: transfer}

% =============================================================================

\outline{\emph{C4:} Evaluation in end-users}{figures/outline_patient.pdf}
\note{
  Now proposed a way to enhance gaze-independent decoding as a proposed
  solution for individuals with eye motor impairment
}

\begin{frame}
  \frametitle{Recruited individuals with physical, \\ speech and eye
  movement}

    \hfill
    \begin{minipage}[t]{.3\textwidth}
      3 Friedreich's \emph{ataxia}
       \begin{itemize}
          \item impaired speech
          \item involuntary eye movements
          \item discomfort fixating
        \end{itemize}
    \end{minipage}\hfill%
    \begin{minipage}[t]{.3\textwidth}
      1 bulbar onset \emph{ALS}
       \begin{itemize}
          \item no speech
          \item minor eye movement impairment
        \end{itemize}
    \end{minipage}\hfill%
    \begin{minipage}[t]{.3\textwidth}
      3 brain stem or cerebellar \emph{stroke}
       \begin{itemize}
          \item no speech
          \item partial eye paralysis
       \end{itemize}
    \end{minipage}
    \hfill
    \bigskip
    \bigskip

    \centering
    Large \emph{individual variety} in preserved skills
    \bigskip
    \bigskip

    \hfill
    \includegraphics[height=.075\textwidth]{figures/logos/uz_leuven.jpg}
    \hfill
    \includegraphics[height=.1\textwidth]{figures/logos/chu_lille.png}
    \hfill
    \includegraphics[height=.05\textwidth]{figures/logos/trainm.png}
    \hfill
    \includegraphics[height=.1\textwidth]{figures/logos/fondation-partage-vie.png}
    \hfill
\end{frame}

\begin{frame}
  \frametitle{Covert visuospatial attention experiment}

  \begin{minipage}{.6\textwidth}
    \includegraphics[height=.45\textwidth]{figures/patients/PD01a-obfuscated.jpg}%
    \hfill%
    \includegraphics[height=.45\textwidth]{figures/patients/PD01b-obfuscated.jpg}%
    \bigskip

    {\small
    \begin{minipage}{.3\textwidth}
      Overt VSA
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_overt.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      Covert VSA
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_covert.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      \small
      Free VSA
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_free.pdf}
    \end{minipage}%
  }
  \end{minipage}


  \aside{
    EEG, EOG and eye-tracking
    \bigskip

    Adapted stimulation parameters
    \bigskip

    Few studies investigating abilities
    \bigskip

    Replace \textit{split} by natural \textit{free}

  }

\end{frame}

\begin{frame}[c]
  \frametitle{Eye tracking}
  \begin{minipage}{.6\textwidth}
    \centering
    \includegraphics[width=.8\textwidth]{figures/patients/fig_gaze.pdf}
  \end{minipage}
  \aside{
    Most prefered to perform overtly
    \bigskip

    Voluntary covert and split did occur


  }
\end{frame}

\begin{frame}
  \frametitle{Subject decoding performance}
  \begin{minipage}{.6\textwidth}
    \resizebox{\textwidth}{!}{
      \input{figures/patients/fig_decode.pgf}
    }
  \end{minipage}
  \aside{
    \small
    Off-line decoder comparison
    \bigskip

    All but one subject above chance
    \bigskip

    Covert was lower than overt, free generally on par
    \bigskip

    Contribution of eye movement
  }
\end{frame}

\begin{frame}
  \frametitle{Recap}
  Visual ERP paradigm
  \begin{itemize}
    \bigskip
  \item[\emph{C1:}] Decoders exploiting spatial-temporal structure
    \bigskip
  \item[\emph{C2:}] Covert attention study with healthy subjects
    \bigskip
  \item[\emph{C3:}] Decoder for eye movement independence \\ accounting for jitter
    \bigskip
  \item[\emph{C4:}] Validation with eye movement impaired subjects
  \end{itemize}
  \aside{%
    Publications
  }
\end{frame}

\begin{frame}
    \frametitle{Conclusions}
    \begin{changemargin}
    \begin{itemize}
      \item Improved decoders enhance BCI \emph{efficiency}
      \bigskip
      \item Improvements in gaze independent decoding improve
        \emph{accessibility} for some
      \bigskip
      \item Gained insight in requirements of BCI users with impaired eye movement
    \end{itemize}
  \end{changemargin}
\end{frame}

\begin{frame}
  \frametitle{Perspectives}
  \begin{changemargin}
    \begin{enumerate}
     \item Integrate BCI and eye-tracking \\ for impaired eye movement
     \bigskip
     \item On-line experiments
     \bigskip
     \item User-centered design study
     \bigskip
     \item Models capturing multi-component and
       non-stationary aspect of (covert) ERPs
  \end{itemize}
  \end{changemargin}
\end{frame}
\note{
  Once the on-line system is available, this allows us to do a proper user
  experience study
}

{

  \setbeamercolor{background canvas}{bg=mylightgray}
\begin{frame}[b]
  \frametitle{Q\&A}
  \hfill \includegraphics[width=.2\textwidth]{figures/logos/logo.png}

\end{frame}
}
%
%%% BACKUP Slides ==============================================================



\begin{frame}[noframenumbering]
  \frametitle{Experimental procedure \\ CVSA-ERP}
  hardware, locations, timings, nr of blocks, ...
\end{frame}
\begin{frame}
  \frametitle{Experimental procedure \\ end-user study}
  hardware, locations, timings, nr of blocks, ...
\end{frame}

\begin{frame}[noframenumbering]

  \frametitle{Block-term tensor discriminant analysis procedure}
  backward model image and equation

  forward model image and equation

  deflation image and equations

  model selection procedure
\end{frame}

\begin{frame}[noframenumbering]

  \frametitle{Block-term tensor discriminant analysis procedure}
  backward model image and equation

  forward model image and equation

  deflation image and equations

  model selection procedure
\end{frame}

\begin{frame}[noframenumbering]
 WCBLE training procedure
\end{frame}

\begin{frame}[noframenumbering]
  WCBLE test procedure
\end{frame}

\begin{frame}[noframenumbering]
  \frametitle{Subjects with physical, speech and gaze impairment}

  \begin{tabular}{@{}l|lrlrl@{}}
      \textbf{ID}  & \textbf{Diagnosis} & \textbf{Age} &
      \textbf{Speech} & \textbf{Trach.} & \textbf{Communication} \\ \hline
      PA1 & bulbar-onset ALS & 58  & absent  & no          & tablet                 \\
      PB1 & Friedreich's ataxia & 41  & impaired & no          & verbal                 \\
      PB2 & Friedreich's ataxia & 43  & impaired & no          & verbal                 \\
      PB4 & Friedreich's ataxia & 48  & impaired & no          & verbal                 \\
      PC2 & brainstem stroke & 43  & absent  & yes         &  eye movement \\
      PC3 & brainstem stroke & 43  & absent  & yes         & letterboard            \\
      PC4 & cerebellar stroke & 54  & absent  & yes         & letterboard \\
  \end{tabular}

\end{frame}



\begin{frame}[noframenumbering]
  \frametitle{Visual skill and eye movement impairment}
  \newcommand{\skill}{}
  \newcommand{\noskill}{x}
  \newcommand{\snoskill}{o}

  \begin{tabular}{l|ccccccc}
                            & PA1      & PB1      & PB2       & PB4      & PC2       & PC3       & PC4 \\ \hline
    \small Visual fixation         & \noskill & \noskill & \noskill  & \noskill & \noskill  & \noskill  & \noskill \\
    \small Eyelid function         & \skill   & \skill   & \skill    & \skill   &  \skill  & \noskill  & \noskill \\
    \small Ocular motility         & \skill   & \noskill & \skill    & \noskill & \snoskill & \snoskill & \noskill\\
    \small Binocular vision        & \skill   & \skill   & \skill    & \skill   & \noskill  & \snoskill & \snoskill \\
    \small Field of vision         & \skill   & \skill   & \skill    & \skill   & \skill    & \noskill  & \noskill \\
    \small Involuntary movement    & \skill   & \noskill & \snoskill  &
    \noskill &  \noskill  & \noskill  & \skill \\ \hline
  Visual acuity (logMAR)  & 0.0      & 0.0      & 0.6       & 0.2      & 0.0       & 0.7  & 0.6\\
  \end{tabular}
  \bigskip

  x: impaired, o: severely impaired
\end{frame}


\begin{frame}[c, noframenumbering]
\frametitle{User-Centered Design}

  \begin{minipage}[c]{.5\textwidth}
  \begin{tabular}{|l|l|}
    \hline
     & \emph{Principles} \\ \hline
     \emph{P1} & understand user, task, environment \\
     \emph{P2} & early and active user involvement \\
     \emph{P3} & driven by user-centered evaluation \\
     \emph{P4} & iterative design \\
     \emph{P5} & adress holistic experience \\
     \emph{P6} & multidisciplinary design \\
    \hline
  \end{tabular}
  \end{minipage}\hfill%
  \begin{minipage}[c]{.4\textwidth}
  \end{minipage}

\end{frame}


\end{document}
