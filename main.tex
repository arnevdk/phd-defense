\documentclass{kul-ulille-beamer}
%\setbeameroption{show notes on second screen=right} % Both


%% Preamble ===================================================================
\usepackage{defense}



% Meta ========================================================================
\addbibresource{references.bib}

\title{%
  A visual Brain-Computer Interface \\
  for gaze-free communication
}
\author{Arne Van Den Kerchove}
\date{December 16, 2024}

\begin{document}
% =============================================================================

\titleframe

% =============================================================================

\begin{frame}
  \frametitle{The Locked-in Syndrome}
  \centering
  \begin{minipage}[c]{.4\textwidth}
    \small
    \raggedright
    Complete paralysis, \\ \emph{impaired communication}
    \bigskip

    Due to
    \begin{itemize}
      \item Stroke
      \item Traumatic brain injury
      \item Neurodegenerative diseases
      \item \ldots
    \end{itemize}
    \bigskip

  Assistive technology
  \bigskip

  A Brain-Computer Interface (BCI) bypasses muscle activity

 \end{minipage}\hfill%
  \begin{minipage}[c]{.5\textwidth}
    \includegraphics[width=\textwidth]{figures/intro/damien.pdf}
  \end{minipage}
\end{frame}
\begin{frame}[noframenumbering]
  \frametitle{The Locked-in Syndrome}
  \centering
  \begin{minipage}[c]{.4\textwidth}
    \small
    \raggedright
    Complete paralysis, \\ \emph{impaired communication}
    \bigskip

    Due to
    \begin{itemize}
      \item Stroke
      \item Traumatic brain injury
      \item Neurodegenerative diseases
      \item \ldots
    \end{itemize}
    \bigskip

  Assistive technology
  \bigskip

    A \emph{Brain-Computer Interface} (BCI) bypasses muscle activity

 \end{minipage}\hfill%
  \begin{minipage}[c]{.5\textwidth}
    \includegraphics[width=\textwidth]{figures/intro/damien_annot.pdf}
  \end{minipage}
\end{frame}



\begin{frame}
  \frametitle{The Brain-Computer Interface}
  \schema{figures/intro/bci.pdf}
\end{frame}


\begin{frame}[c]
  \frametitle{Research question}
  \centering

  \begin{minipage}{.8\textwidth}
  \centering
  \huge
  How can we optimize \emph{BCI}  assistive technology design  to make it more
    \emph{efficient} and  \emph{accessible}?
  \end{minipage}

\end{frame}


% =============================================================================

\outline{Outline}{figures/outline_design.pdf}
{
  \setbeamercolor{background canvas}{bg=mylightgray}
  \begin{frame}[noframenumbering]
  \frametitle{Outline}
    \schema{figures/outline.pdf}
  \end{frame}
}

\begin{frame}[c]
  \frametitle{Recording the brain activity}
  \schema{figures/intro/recording_modalities.pdf}
  \hfill
  \aside{%
    \emph{EEG}  measures the \\ electrical field on the
    scalp:
    \begin{itemize}
      \item[\textcolor{mygreen}{+}] Non-invasive
      \item[\textcolor{mygreen}{+}] Cheap
      \item[\textcolor{myred}{--}] Large scale activity
      \item[\textcolor{myred}{--}] High noise
    \end{itemize}
    \bigskip

    \ergo Account for this in task and decoder design
  }
\end{frame}



%\begin{frame}[c]
%  \frametitle{BCI paradigms for communication}
%  \begin{minipage}[c]{.5\textwidth}
%    \footnotesize
%    \input{figures/intro/paradigms.tikz.tex}
%  \end{minipage}\hfill%
%
%  \aside{%
%    \small
%    %\emph[accent3]{Passive} BCIs not meant for communication
%      \smallskip
%
%      \emph[accent1]{Active} BCIs
%      \begin{itemize}
%        \footnotesize
%        \item[\textcolor{mygreen}{+}] Natural
%        \item[\textcolor{myred}{--}] Invasive for high speed
%      \end{itemize}
%      \bigskip
%
%      \emph[accent2]{Reactive}
%      \begin{itemize}
%        \footnotesize
%        \item[\textcolor{myred}{--}] Continuous stimulation
%        \item[\textcolor{mygreen}{+}] Fast stimulation
%        \item[\textcolor{mygreen}{+}] Suited for EEG
%      \end{itemize}
%      \bigskip
%
%      Fast communication with \\ \emph{visual reactive} paradigm
%    }
%\end{frame}


\begin{frame}
  \frametitle{The visual event-related potential (ERP)  paradigm}
  \begin{minipage}[c]{.4\textwidth}
    \includegraphics[width=\textwidth]{figures/intro/oddball.pdf}
    %\animategraphics[width=\textwidth]{2}{figures/intro/erp_animation}{}{}
    \smallskip

    \begin{tikzpicture}
      \node at (current page.north east) [%
        anchor=north east,
        text width=7cm,
        fill=white, opacity=1,
        xshift=1cm,
        yshift=-.5cm,
        thin
      ]{%
        \input{figures/intro/erp.tikz.tex}
      };
    \end{tikzpicture}

  \end{minipage}\hfill%
  \begin{minipage}[c]{.5\textwidth}
    \begin{enumerate}
      \item Stimuli flash one by one
      \smallskip
      \item Flashes evoke ERPs
      \smallskip
      \item User attends a stimulus
      \smallskip
      \item ERP components are \\ modulated by attention
      \smallskip
      \item Decode target based on \\ timing and components
    \end{enumerate}
  \end{minipage}
\end{frame}


% =============================================================================

\outline{\emph{C1.} Spatial-temporal ERP decoding}{figures/outline_decode.pdf}
\begin{frame}[c]
  \frametitle{\emph{Problem:} ERP responses can be difficult to extract}
  \begin{minipage}[c]{.5\textwidth}

    Strong noise \ergo machine learning decoders
    \begin{itemize}
      \itemnega High number of features
      \itemnega Calibration: low sample size
    \end{itemize}
    \bigskip

    \emph{Solution}: incorporate original \\ data structure
    \begin{itemize}
      \itemposi Regularization
      \itemposi Fast training
    \end{itemize}
  \end{minipage}\hfill%
  \begin{minipage}[c]{.35\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/decode/epoch.pdf}
  \end{minipage}
\end{frame}

\begin{frame}[c]
  \frametitle{Covariance matrix regularization \\
  {\tiny\cite{VanDenKerchove2022}}}
  \begin{minipage}[c]{.3\textwidth}
  \includegraphics[width=\textwidth]{figures/decode/emp_cov.pdf}

    \tiny
    $$(20 \times 17) \times (20 \times 17) = 115600 $$
  \end{minipage}
  $=$\hspace{.3em}
  \begin{minipage}[c]{.3\textwidth}
    \begin{minipage}[c]{.4\textwidth}
      \vspace{2.1em}
      \includegraphics[width=\textwidth]{figures/decode/sp_cov_2.pdf}

      \vspace{-.5em}
      \tiny
      $$20 \times 20 = 400$$
    \end{minipage}
    $\otimes$\hspace{.3em}
    \begin{minipage}[c]{.4\textwidth}
      \vspace{2.1em}
      \includegraphics[width=\textwidth]{figures/decode/tmp_cov_2.pdf}

      \vspace{-.5em}
      \tiny
      $$17\times17 = 289 $$

    \end{minipage}
  \end{minipage}\hfill
  \aside{
    Spatial temporal linear decoders
    \bigskip

    Imprecise due to high number of features
    \bigskip

    Repetitive structure in channels and time
    \bigskip

    Lightweight computation
    \bigskip

    LCMV-beamformer and LDA: improvement for short calibration time \\ {\tiny\cite{Wittevrongel2017}}

  }


\end{frame}

\begin{frame}
  \frametitle{Spatial-temporal feature extraction}

  \begin{minipage}[t]{.35\linewidth}
		\centering
	%	\begin{tikzpicture}[y=-1cm]
	%		\begin{scope}[shift={(-1,0)}]
  %      \TensorThree{$\ten{X}$}{\rotatebox{90}{\small channels}}{\small time points}{}{2}{2}{0}
	%			\node at (3.2,.5, 2) {$\rightarrow$};
	%			\begin{scope}[shift={(3.25,0.25)}]
	%				\TensorThree{$\ten{G}$}{}{}{}{1}{1}{0}
	%			\end{scope}
	%			\node at (4.2,1.25, 2) {$\downarrow$};
	%			\begin{scope}[shift={(3,2)}]
	%				\TensorTwo{classifier}{}{}{1.5}{.5}
	%			\end{scope}
	%		\end{scope}
  %  \end{tikzpicture}
  %  \bigskip
  \includegraphics[width=\textwidth]{figures/decode/hoda.pdf}

    \raggedright\small
    Directly operates on structured data
    \begin{itemize}
      \item Extract features separately in space and time
    \end{itemize}
    {\tiny\cite{Phan2010}}
	\end{minipage}\hfill%
  \vrule\hfill%
  \begin{minipage}[t]{.5\textwidth}
    \centering
		%\begin{tikzpicture}[y=-1cm]
		%	\begin{scope}[shift={(-1,0)}]
		%		\TensorThree{$\ten{X}$}{}{}{}{2}{2}{0}
		%		\node at (3.2,.5, 2) {$\rightarrow$};
		%		\begin{scope}[shift={(3.25,0.25)}]
		%			\TensorThree{$\ten{G}^{(1)}$}{}{}{}{1}{1}{0}
		%		\end{scope}
		%		\node at (5.75,.5,2) {$,\cdots,$};
		%		\begin{scope}[shift={(6.25,0.25)}]
		%			\TensorThree{$\ten{G}^{(B)}$}{}{}{}{1}{1}{0}
		%		\end{scope}
		%		\node at (4.2,1.25, 2) {$\downarrow$};
		%		\node at (5.7,1.25, 2) {$\downarrow$};
		%		\node at (7.2,1.25, 2) {$\downarrow$};
		%		\begin{scope}[shift={(3,2)}]
		%			\TensorTwo{classifier}{}{}{4.5}{.5}
		%		\end{scope}
		%	\end{scope}
    %\end{tikzpicture}
    \includegraphics[width=\textwidth]{figures/decode/bttda.pdf}
    \bigskip

    \small
    \begin{minipage}[t]{.45\textwidth}
      \posi\ \ More flexible
      \smallskip

      \posi\ \ Retains structure
      \smallskip

      {\tiny\cite{VanDenKerchovesubmitted}}
    \end{minipage}\hfill%
    \begin{minipage}[t]{.5\textwidth}
      \raggedright
      \nega\ \ More parameters
      \smallskip

      \ergo Heuristic model selection
    \end{minipage}
      \bigskip

      Validated with benchmarking datasets
  \end{minipage}

\end{frame}



% =============================================================================

\outline{\emph{C2.} Eye movement independence}{figures/outline_gaze.pdf}


\begin{frame}
  \frametitle{\emph{Problem:} Eye motor impairment \\  prevents gazing at targets}

  \begin{minipage}[c]{.4\textwidth}
    \raggedright
    Impairment affects BCI operation
    {\tiny\cite{FriedOken2020}}
    {\small
    \begin{itemize}
      \footnotesize
      \item Discomfort fixating
      \item Restricted movement
      \item Involuntary movements
    \end{itemize}
    }
    No direct gaze
    \bigskip
    \bigskip

    Decoding relies on \emph{visual ERP} components \\ {\tiny\cite{Treder2010}}
  \end{minipage}\hfill%
  \begin{minipage}[c]{.55\textwidth}
		\centering
		\includegraphics[width=\textwidth]{figures/covert/performance.pdf}

    \raggedleft{\tiny\cite{RonAngevin2019}}


	\end{minipage}
\end{frame}

\begin{frame}
  \frametitle{Covert visuospatial attention experiment \\
    {\tiny\cite{VanDenKerchove2024}}}
    \centering

    \small
    \begin{minipage}{.6\textwidth}
    \begin{minipage}{.3\textwidth}
      overt
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_overt.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      covert
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_covert.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      \small
      split
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_split.pdf}
    \end{minipage}%
    \end{minipage}
    \bigskip


    \hfill
    \begin{minipage}[c]{.25\textwidth}
    \input{figures/covert/interface_3.tikz.tex}
      Hex-o-Spell {\tiny\cite{Treder2010}}
    \end{minipage}\hfill%
    \begin{minipage}[c]{.3\textwidth}
      \includegraphics[width=\textwidth]{figures/covert/timeline.pdf}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.25\textwidth}
      \begin{itemize}
        \item simulate with 15 healty control subjects
        \item randomized dual attention and gaze task
      \end{itemize}
    \end{minipage}

\end{frame}

\begin{frame}
  \frametitle{Absence of visual ERP components}
  \footnotesize
  \begin{minipage}[t]{.45\textwidth}
    \includegraphics[width=.2\textwidth]{figures/covert/attention_overt.pdf}
    \hspace{.5em}
    \emph{overt}
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_overt_cluster-1.pdf}
    Attention-based P3 (central-parietal)
    \bigskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_overt_cluster-0.pdf}
    Visual early components (occipital)
    \smallskip

  \end{minipage}\hfill%
  \begin{minipage}[t]{.45\textwidth}
    \includegraphics[width=.2\textwidth]{figures/covert/attention_covert.pdf}
    \hspace{.5em}
    \emph{covert}
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_covert_cluster-0.pdf}
    \smallskip

    \includegraphics[width=.2\textwidth]{figures/covert/attention_split.pdf}
    \hspace{.5em}
    \emph{split}
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/erps/erp_split_cluster-0.pdf}

  \end{minipage}
  \centering
  \smallskip

  {\tiny F-statistic cluster-based permutation tests}
\end{frame}


%% =============================================================================

\outline{\emph{C3.} Eye movement independent decoding}{figures/outline_decode.pdf}

\begin{frame}[c]
  \frametitle{\emph{Problem:} Latency jitter decreases performance \\ in covert and split
  attention}
  \begin{minipage}{.4\textwidth}
    \input{figures/covert/smearing.tikz.tex}
  \end{minipage}\hfill%
  \begin{minipage}{.55\textwidth}

    \small
    \hspace{3.25em}\emph{CVSA-ERP}\hspace{6.45em}\emph{BNCI2014-009}
    \smallskip

    \centering
    {\centering\resizebox{.7\textwidth}{!}{%
    %CVSA-ERP (our dataset) \hspace{3.5em} BNCI2014-009
    %\smallskip
    \input{figures/covert/jitter.pgf}
    }}

    \begin{itemize}
      %\item Classifier-based latency estimation {\tiny\cite{Mowla2017}}
      \item Higher jitter when eye movement independent
      \item Contributes to low accuracy \\ {\tiny\cite{Arico2014}}
      \item Can this be \emph{accounted for}?
    \end{itemize}

  \end{minipage}

\end{frame}

\begin{frame}
  \frametitle{Latency estimation and alignment}
  \begin{minipage}{.3\textwidth}
    \centering
    \emph{Before} alignment
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/align_before.pdf}
  \end{minipage}
  \begin{minipage}{.3\textwidth}
    \centering
    \emph{After} alignment
    \smallskip

    \includegraphics[width=\textwidth]{figures/covert/align_after.pdf}
  \end{minipage}
  \aside{%
    Developed enhanced ERP latency estimation method
    {\tiny\cite{VanDenKerchove2024,Mowla2017}}
    \bigskip

    Iterative alignment
    \bigskip

    Improves latency estimation in simulated data
    \bigskip

    Useful in BCI setting?
  }
\end{frame}


\begin{frame}
  \frametitle{Application to eye movement independent \\ decoding}
  \begin{minipage}{.6\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/covert/roc_auc_diff.pdf}
  \end{minipage}\hfill
  \aside{%
    Applicable as decoder
    \bigskip

    Within-subject, cross-validated ROC-AUC
    \bigskip

    Compared with state-\\of-the art decoder (tLDA) \\
    {\tiny\cite{Sosulski2022}}
    \bigskip

    Improves covert and split decoding performance


  }
\end{frame}

% =============================================================================

\outline{\emph{C4:} Evaluation in end-users}{figures/outline_patient.pdf}

\begin{frame}
  \frametitle{Participants with physical, speech and eye movement
  impairment}

    Large \emph{individual variety} in preserved skills

    \vfill


    \hfill
    \begin{minipage}[t]{.3\textwidth}
      3 Friedreich's \emph{ataxia}
       \begin{itemize}
          \item impaired speech
          \item involuntary eye movements
          \item discomfort fixating
        \end{itemize}
    \end{minipage}\hfill%
    \begin{minipage}[t]{.3\textwidth}
      1 bulbar onset \emph{ALS}
       \begin{itemize}
          \item no speech
          \item minor eye movement impairment
        \end{itemize}
    \end{minipage}\hfill%
    \begin{minipage}[t]{.3\textwidth}
      3 brain stem or cerebellar \\ \emph{stroke}
       \begin{itemize}
          \item no speech
          \item partial eye paralysis
       \end{itemize}
    \end{minipage}
    \hfill

    \vfill

    \hfill
    \includegraphics[height=.075\textwidth]{figures/logos/uz_leuven.jpg}
    \hfill
    \includegraphics[height=.1\textwidth]{figures/logos/chu_lille.png}
    \hfill
    \includegraphics[height=.05\textwidth]{figures/logos/trainm.png}
    \hfill
    \includegraphics[height=.1\textwidth]{figures/logos/fondation-partage-vie.png}
    \hfill
\end{frame}

\begin{frame}
  \frametitle{Covert visuospatial attention experiment}

  \begin{minipage}{.6\textwidth}
    \centering
    \hfill
    \includegraphics[height=.45\textwidth]{figures/patients/setup.pdf}%
    \hfill%
    \bigskip
    \bigskip

    {\small
    \begin{minipage}{.3\textwidth}
      overt
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_overt.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      covert
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_covert.pdf}
    \end{minipage}\hfill%
    \begin{minipage}{.3\textwidth}
      \small
      \emph{free}
      \smallskip

      \includegraphics[width=\textwidth]{figures/covert/attention_free.pdf}
    \end{minipage}%
  }
  \end{minipage}


  \aside{
    EEG, EOG and eye-tracking
    \bigskip

    Adapted stimulation parameters
    \bigskip

    Few studies investigating abilities
    \bigskip

    Replace \textit{split} by natural \textit{free}

  }

\end{frame}


{
\setbeamercolor{background canvas}{bg=black}
\begin{frame}[c]
  \frametitle{\textcolor{mylightgray}{Eye tracking}}
  \begin{minipage}{.6\textwidth}
    \centering
    \includegraphics[width=.8\textwidth]{figures/patients/fig_gaze_defense.png}
  \end{minipage}
  \aside{
    Most used overt attention
    \bigskip
    \bigskip

    1 participant covert
    \bigskip
    \bigskip

    1 participant split
    \bigskip
    \bigskip

  }
\end{frame}
}

\begin{frame}
  \frametitle{Subject decoding performance}
  \begin{minipage}{.6\textwidth}
    \includegraphics[width=\textwidth]{figures/patients/fig_decode.pdf}
  \end{minipage}
  \aside{
    \small
    Off-line decoder comparison,
    similar performance
    \bigskip

    Most above chance, positive effect for some
    \bigskip

    Covert lower than overt
    \bigskip

    Free not always worse
    \bigskip

    \ergo Contribution of gaze
  }
\end{frame}

\begin{frame}
  \frametitle{Recap}
  Make BCI-AT more \emph{efficient} and \emph{accessible}\\ using the \emph{visual
  ERP} paradigm
  \begin{itemize}
    \bigskip
  \item[\emph{C1:}] Decoders exploiting spatial-temporal structure
    \bigskip
  \item[\emph{C2:}] Covert attention study with healthy subjects
    \bigskip
  \item[\emph{C3:}] Decoder for eye movement independence \\ accounting for jitter
    \bigskip
  \item[\emph{C4:}] Validation with eye movement impaired subjects
  \end{itemize}
  \begin{refsection}[publications.bib]
  \aside{
    Publications
    \tiny
    \setlength{\leftmargini}{2em}
    \begin{itemize}
      \item Libert, A. et al. (2022). ``Analytic
        beamformer transformation for
        transfer learning in motion-onset
        visual evoked potential decodin''.
        en. In: \textit{Journal of Neural
        Engineering} 19.2, p. 026040.
      \item Van Den Kerchove, A. et al. (2022).
        ``Classiﬁcation of Event-Related
        Potentials with Regularized
        Spatiotemporal LCMV
        Beamforming''. In: \textit{Applied Sciences}
        12.6, p. 2918.
      \item Van Den Kerchove, A. et al. (2024).
        ``Block-Term Tensor Discriminant
        Analysis for Brain-Computer
        Interfacing''. In: \textit{Journal of Neural
        Engineering.} Submitted for
        publication.
      \item Van Den Kerchove, A. et al. (2024a).
        ``Correcting for ERP latency jitter
        improves gaze-independent BCI
        decoding''. In: \textit{Journal of Neural
        Engineering.}
      \item Van Den Kerchove, A. et al.
        ``Case studies of the impact of eye
        motor impairment on visual ERP
        BCI usage''. In preparation.
    \end{itemize}
  }
  \end{refsection}
\end{frame}

\begin{frame}
    \frametitle{Conclusions}
    \begin{changemargin}
    \begin{itemize}
      \item Improved decoders enhance BCI \emph{efficiency}
      \bigskip
      \item Improvements in eye movement independent decoding improve
        \emph{accessibility} for some
      \bigskip
      \item Occasionaly impacts end-users, need for holistic approach beyond
        decoder design
      \bigskip
      \item Gained insight in requirements of BCI users with impaired eye movement
    \end{itemize}
  \end{changemargin}
\end{frame}

\begin{frame}
  \frametitle{Perspectives}
  \begin{changemargin}
    \begin{enumerate}
     \item Integrate BCI and eye-tracking \\ for impaired eye movement
     \bigskip
     \item On-line experiments
     \bigskip
     \item User-centered design study
     \bigskip
     \item Models capturing multi-component and
       non-stationary aspect of (covert) ERPs
  \end{enumerate}
  \end{changemargin}
\end{frame}

\outline{Q\&A}{figures/qa.pdf}
%
%%% BACKUP Slides ==============================================================

\begin{frame}[noframenumbering]
  \centering

  \frametitle{Gaze-independent visual reactive BCIs}

  \begin{minipage}{.3\textwidth}
    \footnotesize
    \begin{itemize}
      \item Auditory
      \item Tactile
      \item Visual
      \smallskip

      \item ERP
      \item SSVEP
      \item Localized covert attention shift
    \end{itemize}
  \end{minipage}\hfill%
  \begin{minipage}{.3\textwidth}
  \includegraphics[width=\textwidth]{figures/supp/feature_hexospell.png}
  \end{minipage}\hfill%
  \begin{minipage}{.3\textwidth}
  \includegraphics[width=\textwidth]{figures/supp/gibs.png}
  \end{minipage}\hfill%

  \bigskip
  \bigskip

  \includegraphics[width=.7\textwidth]{figures/supp/rsvp.png}

\end{frame}


\begin{frame}[noframenumbering]
  \frametitle{Kronecker-Toeplitz structured \\ spatiotemporal covariance matrix estimation}
  \scriptsize
  \begin{minipage}{.2\textwidth}
		$$
      \tilde{\mat{S}}_{k+1} =
			\frac{1}{N}
      \sum^N_{n=1}\mat{X}_n^\intercal\hat{\mat{T}}_k^+\mat{X}_n
			\label{eq:stbf-struct/fpi-spatial}
		$$
		$$
      \tilde{\mat{T}}_{k+1} =
			\frac{1}{N}
      \sum^N_{n=1}\mat{X}_n\hat{\mat{S}}_k^+\mat{X}_n^\intercal
			\label{eq:stbf-struct/fpi-temporal}
		$$
  \end{minipage}\hfill\vrule\hfill%
  \begin{minipage}{.4\textwidth}
		$$
      \tilde{\mat{S}}_{k+1}^{(\beta)} =
      (1-\beta_{k+1})\tilde{\mat{S}}_{k+1}
      +\beta_{k+1}\frac{\Tr(\tilde{\mat{S}}_{k+1})}{C}\mathbb{I}
			\label{eq:stbf-struct/fpi-spatial-shrunk}
		$$
		$$
      \tilde{\mat{T}}_{k+1}^{(\gamma)} =
      (1-\gamma_{k+1})\tilde{\mat{T}}_{k+1}
      +\gamma_{k+1}\frac{\Tr(\tilde{\mat{T}}_{k+1})}{S}\mathbb{I}
			\label{eq:stbf-struct/fpi-temporal-shrunk}
		$$
  \end{minipage}\hfill\vrule\hfill%
  \begin{minipage}{.2\textwidth}
		$$
      \hat{\mat{S}}_{k+1} =
      \frac{C}{\Tr\left[\tilde{\mat{S}}_{k+1}^{(\beta)}\right]}
      \tilde{\mat{S}}_{k+1}^{(\beta)}
			\label{eq:stbf-struct/fpi-spatial-norm}
		$$
		$$
      \hat{\mat{T}}_{k+1} =
      \frac{S}{\Tr\left[\tilde{\mat{T}}_{k+1}^{(\gamma)}\right]}
      \tilde{\mat{T}}_{k+1}^{(\gamma)}
			\label{eq:stbf-struct/fpi-temporal-norm}
		$$
  \end{minipage}


\end{frame}

\begin{frame}[noframenumbering]
  \small

  \frametitle{Block-term tensor discriminant analysis procedure}
  \begin{minipage}[t]{.5\textwidth}
    HODA \emph{backward} model
    \bigskip

    \resizebox{.65\textwidth}{!}{
      \input{figures/bttda/figure2.tikz.tex}
    }
  \end{minipage}\hfill%
  \begin{minipage}[t]{.5\textwidth}
    HODA \emph{forward} model
    \smallskip
    \hfill

    \resizebox{\textwidth}{!}{
      \input{figures/bttda/figure3.tikz.tex}
    }
  \end{minipage}
  \vfill

  \begin{minipage}[c]{.5\textwidth}
  \bigskip
  BTTDA forward model
  \smallskip

    \resizebox{\textwidth}{!}{
      \input{figures/bttda/figure4.tikz.tex}
    }
  \end{minipage}\hfill%
  \begin{minipage}[c]{.5\textwidth}
  \tiny

	$$\left\{\mat{U}^*\right\}  = \frac{\sum_c^CN_c\left\|\bar{\ten{G}}(c)-\bar{\bar{\ten{G}}}\right\|_F^2}
	{\sum_n^N\left\|\ten{G}(n)-\bar{\ten{G}}(c_n)\right\|_F^2}$$

	$$\mat{A}_k = \argmin_{\mat{A}_k}
	\sum_n^N\left[\mat{X}_k(n) -
		\mat{A}_k\left(\ten{G}(n)\mmprs{\mat{A}}{k}\right)_k\right]^2$$

  $$\ten{G}^{(b)} = \ten{E}^{(b-1)}\mmpr{\mat{U}^{(b)}}$$



  \end{minipage}
\end{frame}

\begin{frame}[noframenumbering]
  \frametitle{Classifier-based latency estimation with Woody iterations (train)}
  \centering
  \includegraphics[width=.6\textwidth]{figures/covert/figure1.pdf}
\end{frame}

\begin{frame}[noframenumbering]
  \frametitle{Classifier-based latency estimation with Woody iterations (test)}
  \centering
  \includegraphics[width=.6\textwidth]{figures/covert/figure2.pdf}
\end{frame}

\begin{frame}[noframenumbering]
  \frametitle{Subjects with physical, speech and gaze impairment}

  \begin{tabular}{@{}l|lrlrl@{}}
      \textbf{ID}  & \textbf{Diagnosis} & \textbf{Age} &
      \textbf{Speech} & \textbf{Trach.} & \textbf{Communication} \\ \hline
      PA1 & bulbar-onset ALS & 58  & absent  & no          & tablet                 \\
      PB1 & Friedreich's ataxia & 41  & impaired & no          & verbal                 \\
      PB2 & Friedreich's ataxia & 43  & impaired & no          & verbal                 \\
      PB4 & Friedreich's ataxia & 48  & impaired & no          & verbal                 \\
      PC2 & brainstem stroke & 43  & absent  & yes         &  eye movement \\
      PC3 & brainstem stroke & 43  & absent  & yes         & letterboard            \\
      PC4 & cerebellar stroke & 54  & absent  & yes         & letterboard \\
  \end{tabular}

\end{frame}



\begin{frame}[noframenumbering]
  \frametitle{Visual skill and eye movement impairment}
  \newcommand{\skill}{}
  \newcommand{\noskill}{x}
  \newcommand{\snoskill}{\emph{o}}

  \begin{tabular}{l|ccccccc}
                            & PA1      & PB1      & PB2       & PB4      & PC2       & PC3       & PC4 \\ \hline
    \small Visual fixation         & \noskill & \noskill & \noskill  & \noskill & \noskill  & \noskill  & \noskill \\
    \small Eyelid function         & \skill   & \skill   & \skill    & \skill   &  \skill  & \noskill  & \noskill \\
    \small Ocular motility         & \skill   & \noskill & \skill    & \noskill & \snoskill & \snoskill & \noskill\\
    \small Binocular vision        & \skill   & \skill   & \skill    & \skill   & \noskill  & \snoskill & \snoskill \\
    \small Field of vision         & \skill   & \skill   & \skill    & \skill   & \skill    & \noskill  & \noskill \\
    \small Involuntary movement    & \skill   & \noskill & \snoskill  &
    \noskill &  \noskill  & \noskill  & \skill \\ \hline
  Visual acuity (logMAR)  & 0.0      & 0.0      & 0.6       & 0.2      & 0.0       & 0.7  & 0.6\\
  \end{tabular}
  \bigskip

  \emph{x}: impaired, \emph{o}: severely impaired
\end{frame}


\begin{frame}[c, noframenumbering]
\frametitle{User-Centered Design}

  \begin{minipage}[c]{.5\textwidth}
  \begin{tabular}{|l|l|}
    \hline
     & \emph{Principles} \\ \hline
     \emph{P1} & understand user, task, environment \\
     \emph{P2} & early and active user involvement \\
     \emph{P3} & driven by user-centered evaluation \\
     \emph{P4} & iterative design \\
     \emph{P5} & adress holistic experience \\
     \emph{P6} & multidisciplinary design \\
    \hline
  \end{tabular}
  \end{minipage}\hfill%
  \begin{minipage}[c]{.45\textwidth}
    \includegraphics[width=\textwidth]{figures/supp/ucd.png}
    \bigskip

    Evaluate
    \begin{itemize}
      \item effectiveness
      \item efficiency
      \item user satisfaction
    \end{itemize}
  \end{minipage}

\end{frame}


\end{document}
