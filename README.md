# phd-defense

## TODO:

* Move notes to slides
* Backup slides for all reviewers based on review questions
* check dissertation for conclusions, limitations, recap (conclusion per topic)
* and perspectives

* Move patient tables to supplementary

* UCD schematic and reference
* Refernce own paper at decoding
* Less text on slides, shorter sentences, kernachtig
* 2: LiS: complete paralysis, indicate assistive technology, indicate EEG, need
  to bypass muscle activity - > BCI
* inclusive->accessible
* Remove slide 8
* 6: remove ERP, not introduced yet
* 9: ERP abbreviation in tile
* slide 10: electrode en tijd bij EEG data
* 11: replace figure by EEG data slide 10
* Time axis in one direction
* Short calibration <- low sample size
* 2 auteurs
* Remove tensor wording
* Connect 13 and 14
* Eye movement independence 15
* Make text slide 1 more descriptive: Oogmotoriek is affected -> cannot gaze,
  maar decoding relies on visual ERPs. -> attended but gazed at is higher than
  attended not gazed at, relabel graph r put own graph, toon covert en overt
  boven graph, don't talk about patients yet
* 17: remove dataset abbreviations, hex-o-spell underneath interface, drop
  sidebar
* 18: covert and split indicate missing component, yellow is significant
* 20: how can this be accounted for/tackled, less verbose, CBLE not explained,
* 22: our model vs state-of-the-art, only left graph, label better worse
* label heatmap: instructed target, arrow gaze
* 28: show only our decoder, mention others performed similarly
* 29: gathered data to investigate effect of eye movement, drop 'iterative
  alignment' -> eye movement independent decoder jitter, Merge decoders in 'proposed new decoders', drop off-line
* swap conclusions and recap/merge
* Perspectives: Integrate EEG and eye-tracking for eye motor impairment
* Merge 11 en 12
* 14: label assen, write classifier full
* Logo's
* Backup slides
* TODO: de clue: we moeten met deze ruis omgaan in paradigm and decoder design
* TODO: je kan de hersenactiviteit wel opnemen, maar dat is pas nuttig als de
  gebruiker een bepaalde taak aan het uitvoeren is zodat we weten welke
  activiteit we eruit moeten halen
* TODO: Goal of communication paradigm fast transfering of information in communication assisted technology
* slide ERP paradigm: stimuli represent discrete choices, e.g.virtual keyboard
* Uniform layout slides, font size
* Missing: linking, transitions
* make contributions clear: C means contribution
* conclusion should preempt some questions
* Goal: assumptions:
   cognitive ability is kept
   able to perform the task
* Put keywords in slide
* First: cannot focus attention
  Second: algorithm cannot cope with jitter
* Put 'targets flash' in slide
* 80% thing quickly mention
* Up to slide 20, at no point methodlology was mentioned
  (public dataset, own  dataset, how...)
* BEfore comparing with SOTA, state it, mention that from now on
* Start with people cannot control gaze three cases:
  1. gaze directly at
  2. gaze empty portion
  3. gaze at different
* label axes
* chose this options from non-invasive, where situated, show active, passive,
  reactive. active less options non-invasive, passive not meant for fast
  communication, reactive holds greater potential
* Remove third axis from HODA
* Interpret graph before making statements about it
* make graphs less complicated
* recap, how we improved on the state of the art, add publications list
* slide 16: make graph more readable, don't put images just to make serious, talk
about it and make it interpretable, explain axes
* slide 18: add text here, explain axes
* make gaze heatmap more clear
* mention eye motor control when mentioning inclusiveness
* drop passive, don't spend time on active and reactive
* slide 8: only say what's necessary
* slide 8: intuitive and self-paced true?
* Slide 12: too much time
* Machine learning models that use the entire set of data points as features
features is data without structure
merge 11 and 12: machine learning -> feature (flattened) but loses structure
and large (negative effect on calibration time and calculation time)
* 13: add numbers
* 14: remove tensors, extracting features seperately in space and time, add
  flattening, add flattened, add size add size
* 18: show distractor ERP
* 20: remove bottom 2 plots, remove the average
* 26: vsa
* 26: free not comfort but: does split and overt it occur? what are they doing when there is no
fixation point
* 29: recap: shorter, to the point, link to contributions
* Conclusions: highlight that we've reached our goals
* Drop 'limited effect on end-users'
* Perspective order:
  1. Integrate eye tracking
  2. On-line
  3. User experience study following user-centric design principles
  4. if need, improve models
* User centered design in perspectives
* Q&A slide: put video of patient typing
* cut negative stuff
* Don't mention comfort, see if split or covert actually happens,
* Heatmap, more contrast, also remove VSA
* Merge 25 and 24, summarize tables, don't know what to say about it
* Flicker gif
* 17: only one arrow
* Drop VSA
* 21: ESTIMATION
* Not necessary to put total number of slides or don't include extra slides
* Remove bottom alignment plot
* 27: Drop eye tracker explanation, drop bottom row
 Add main message: could all mobe eyes a little bit
* 28: put legend lower
  Explain decoders
  Explain graph
* 29: drop number of decoders
* Avoid gaze independent
* 18: Explain clusters ir drop
* 22: say left is better
* Never use CBLE, WCBLE
* 21:  SHORTER Sentences
* 21: drop age and trach, drop patient letters
* 26: purple shirt
* 8: drop passive, indicate visual reactive on slides
* 7: cannot determine where signals originate from
* 8: make less dense
* 26: indicate eye tracker, laptop, eeg cap
* Never say gaze- independent, say independent of eye movements


Questions from jury:
* Is it working or not
* Is it open
* add channel map in backup slide
* Go through questions in report, prepare 1 slide/answer for all their remarks
